# vim:ft=zsh wrap

# memorize
v ~/dots/memorize
v ~/dots/snips/
v ~/dots/config/nvim/words
v ~/dots/config/mise/config.toml
v $(mise config | grep '.mise.toml' | awk '{print $1}' | perl -pe 's/~/$ENV{"HOME"}/')  ## open near mise config

# open macos
open /Applications

# bookmark
open -a 'Google Chrome.app' https://lzone.de/cheat-sheet  ## cheatsheet Redis, MySQL, ElasticSearch...
open -a 'Google Chrome.app' https://docs.github.com/en/actions/creating-actions/creating-a-composite-action ## github workflow composite action
open -a 'Google Chrome.app' https://www.shellcheck.net  ## shell script checker
open -a 'Google Chrome.app' 'https://github.com/search?q=topic%3Acustom-elements+org%3Agithub&type=repositories' ## github의 web component
open -a 'Google Chrome.app' 'https://railsg.xyz' ## rails command generator
open -a 'Google Chrome.app' 'https://docs.docker.com/compose/compose-file/build/' ## open docker reference
open -a 'Google Chrome.app' 'https://grep.app'  ## search projects in git repo
open -a 'Google Chrome.app' 'https://http.cat'  ## http status code
open -a 'Google Chrome.app' 'https://carbon.now.sh/'  ## terminal command line to image, capture, twitter
open -a 'Google Chrome.app' 'https://excalidraw.com'  ## draw diagram
open -a 'Google Chrome.app' 'https://endoflife.date'  ## EOL
open -a 'Google Chrome.app' 'https://www.calculator.net/ip-subnet-calculator.html?cclass=b&csubnet=20&cip=10.10.0.0&ctype=ipv4&printit=0&x=83&y=15'  ## open subnet calculator

# macos
security add-generic-password -a $LOGNAME -T "" -U -s 'test-pass' -w 'PASS'  ## Save password to keychian
security find-generic-password -a $LOGNAME -s 'test-pass' -w  ## Get password from keychain
security delete-generic-password -a $LOGNAME -s 'test-pass'  ## Delete password from keychain

brew install 1password-cli  ## Need `preference > developer > integrate with 1Password CLI` OR `op signin`
op vault ls  ## 1password get vault
op item ls --vault 'VAULT'  ## 1password get items
op item get 'ITEM' --field 'token' --vault 'VAULT'  ## 1password get specific field
op item get 'ITEM' --vault 'VAULT' --format json  ## 1password get json
op item create --vault 'VAULT' --title 'APIKey' --category 'Login|Secure Note|Password' "token=..." "username=foo" ..
op document create config.yaml --vault 'VAULT' --title 'config.yaml'  ## if want update. delete and recreate
op item create --vault 'VAULT' --template ./item.json  ## .title, .vault, .category, .fields[{ .label, .value }]
op item edit 'APIKey' --vault 'VAULT' "token=..."
op run --env-file="./prod.env" -- aws  ## AWS_ACCESS_KEY="op://<vault>/<item>/<field>/access_key_id"
op inject -i .env.tpl -o .env  ## AWS_ACCESS_KEY="op://<vault>/<item>/<field>/access_key_id"
op read "op://<vault>/<item>/<field>/access_key_id"

system_profiler SPBluetoothDataType | yq '.Bluetooth.Connected.HHKB-Studio1.["Battery Level"]'


# bash
echo '\033[31mRed!\033[0m'  ## color 30~ KRGY BMCW; 1:bold 5:blink 7:invt
2>&1 | tee -a ~/tmp/tee/stdout-$(date +"%y%m%d_%H%M").log
netstat -vanp tcp | grep LISTEN  ## check open ports
lsof -i -P | grep LISTEN  ## check open ports
ssh-keygen -t ed25519 -C "user@example.com"
ssh-keygen -f ~/.ssh/id_ed25519 -y  ## public key
date +"%Y-%m-%dT%H:%M:%S%z"  ## iso-8610 in BSD

ssh -L 8080:localhost:80 user@remote -N ## local port forward. curl localhost:8080 -> localhost:80 in remote

join -a 1 -a 2 -e "-" -o '0,1.2,2.2' /tmp/before.txt /tmp/after.txt  ## key,name file outer join

openssl req -new -newkey rsa:4096 -x509 -sha256 -days 365 -nodes -out cert.crt -keyout cert.key
openssl rand -hex 16  ## generate random password

for i in {1..100}; do echo $i; done
for i in $(echo $res); do echo $i; done  ## iterate variable line by line
tmux send-keys -t $(tmux split-window -d -P -F "#{pane_id}" 'ssh temp0') 'ls' Enter
for i in {0..6}; do tmux send-keys -t $(tmux split-window -d -P -F "#{pane_id}" "ssh temp$i") 'ls' Enter; tmux select-layout tiled; done
tmux capture-pane -J -p -S - -t $TMUX_PANE > /tmp/pane.log  ## tmux save to logs ;; -S - : from start ;; -p : to stdout ;; -J : wrapped lines join ;; -t : target. %123

| cut -c-$COLUMNS
| while read -r line; do echo $line; done

systemctl --type=service --state=active
systemctl --type=service --state=running
jounalctl -u $UNIT -n 100 -f

sudo apt install -y libssl-dev libbz2-dev libreadline-dev libffi-dev liblzma-dev libsqlite3-dev  ## python build dependency in ubuntu

rsync --progress --stats -avr /mnt/from/ /mnt/to/  ## from/xx.txt -> to/xx.txt ;; from 뒤에 / 붙으면 파일만, 없으면 폴더 그 자체가 대상 ;; -a : recursive, link(sym), permission, times, group, owner, Devices ;; --max-size 100m : 크기를 넘는 파일은 전송안함 ;; --bwlimit 10m : 전송속도 제한 ;; --exclude-from - <<EOF : *.zip, *.html 등 stdin, heredoc, file 형태로 제외할 파일 지정 ;; --partial : 파일 전송을 부분적으로 보관
rsync -Pvr --exclude=node_modules --exclude=vendor /mnt/from /mnt/to  ## from/xx.txt -> to/from/xx.txt

# bash : bulk edit
rg --color=never -l ${SEARCH} | xargs perl -i -pe 's/${SEARCH}/xxx/g'  ## find all replace
rg --color=never -l ${SEARCH} | while read -r line; do echo $line; done;  ## loop search files
vim -Nens +'g/namespace/norm nciwname' +wq file.txt  ## all replace ;; # e: ExMode / s: Silent / n: No Swap. memory only / N: nocompatible
vim -Nens +'bufdo g/namespace/norm nciwname' +wqa file.txt file2.txt  ## multiple all replace
| vim -e -s +%s/s/k/ +%p -cq! /dev/stdin  ## +wq!, ZZ 로 저장후 종료 ;; + : cmd ;; - : normal
| vim -es +'norm dw' +%p +q! /dev/stdin

env $(cat .env | xargs) envsubst < <(echo 'x: ${A}')  ## envsubst with .env file
echo 'cat <<EOF' > tmp.sh && cat x.yaml >> tmp.sh && echo 'EOF' >> tmp.sh && bash tmp.sh > res.yaml && rm tmp.sh  ## primitive envsubst

# ruby
ruby -Itest test/**
bundle exec rails
bundle exec sidekiq
bundle exec ruby -Itest ${TEST}  ## ruby test
bundle config set --local path .bundle  ## 사용할 .bundle 경로 지정
bundle config set --local path vendor/bundle
bundle config set --local cache_path vendor/bundle/cache
bundle config set --local force_ruby_platform true
bundle config set --local jobs 4
bundle config set --local retry 3
bundle config set --local clean true
bundle config build.pg --with-pg-config=$(brew --prefix libpq)/bin/pg_config
bundle config build.mysql2 --with-mysql-dir=$(brew --prefix mysql-client)
bundle config build.iconv --with-iconv-dir=$(brew --prefix libiconv)
bundle config build.iconv --with-cflags="-Wno-incompatible-function-pointer-types"
bundle config build.nio4r --with-cflags="-Wno-incompatible-function-pointer-types"
bundle config build.nokogiri --with-iconv-dir=$(brew --prefix libiconv)
brew install libpq  ## install postgres library
gem bump -v pre  ## gem install gem-release

ruby -run -e httpd . -p 8000
ruby -rlisten -e 'Listen.to("./"){ %x{} if _1.count>0 }.then{ _1.start; _1.only // }; sleep'

ruby -r sequel -r irb -e 'DB = Sequel.connect(ENV[:DB_URL.to_s]); IRB.start'
ruby -r sequel -r irb -e 'DB = Sequel.sqlite("x.db"); puts "ex: DB.tables\nex: DB[:user].where(name: :abc)"; IRB.start'  ## require `gem install sqlite3 sequel`
ruby -r sequel -r irb -e 'DB = Sequel.postgres("dbname", user: "", password: "", host: ""); IRB.start'  ## require `gem install pg sequel`
ruby -r sequel -r irb -e 'DB = Sequel.connect("postgres://user:password@localhost/my_db"); IRB.start'  ## require `gem install pg sequel`
ruby -r openssl -e 'puts OpenSSL::OPENSSL_VERSION'
ruby -r erb -e 'puts ERB.new(File.read "./temp.tt").result_with_hash(name: ARGV.first)' name  ## erb template
ruby -r active_support/all -e 'puts "asdf".camelize.underscore'
| xargs -I{} ruby -rerb -e 'File.write "./#{ARGV.first.downcase}.rb", ERB.new(File.read "./temp.tt").result_with_hash(name: ARGV.first)' {}
| ruby -rjson -e 'puts JSON[STDIN.read, symbolize_names: true]'  ## input json: '{"a":[...]}'
| ruby -rnokogiri -e 'puts Nokogiri::XML(STDIN.read)'  ## input XML
| ruby -e 'puts STDIN.read.to_i(16)'  ## hex to integer
| ruby -e 'puts STDIN.read.scan(/.{1,2}/).map { _1.to_i(16).chr }.join'  ## hex to string 1
| ruby -e 'puts [STDIN.read].pack("H*")'  ## hex to string 2. (Hex, Char, Short, Long, ascii etc..)
| ruby -e 'puts Time.at(STDIN.read.gsub(/[^\d]/, "").to_i)'  ## epoch, unix time
| ruby -rcsv -rcgi -e 'CSV.parse(STDIN, headers: true).each { |row| row[2].split("?").last.then { CGI.parse _1 }.then { puts _1.fetch "q", nil } }'  ## CSV parse & get query param

echo "\nActiveRecord::Base.establish_connection(adapter: 'postgresql', host: 'localhost', port: 5432, username: 'postgres', password: 'postgres', database: 'dev');\nclass User < ApplicationRecord; self.table_name = 'users' end;\nUser.all\n"; bundle exec rails c  ## attach specific database
find test -name '*.rb' -type f -mtime -30m -exec ls -t {} + | head -n 1 1>&2 | xargs bundle exec rails test  ## test recently modified file

bin/rails rswag
bin/rails g rspec:swagger API::V1::MyController
bin/rails test -v | tee >(grep -E 'Test#' | perl -lne '/^(.+Test#.+?) = (.+?) s/; print "$2 $1"' | sort -nr)
bin/rails test -v | tee >(perl -lne 'print "\n====" if /^Failure:/; print if /^Failure:/../^rails test/') >(grep -E 'Test#' | perl -lne '/^(.+Test#.+?) = (.+?) s/; print "$2 $1"' | sort -nr | perl -pe '$.==1 and print "\n# Duration Time\n"')
bin/rails routes --expand
bin/rails g scaffold_controller 'm/model' index show
watch -cn1 bundle exec rspec --force-color spec/**  ## watch test in rspec rails

bin/rails g model User email:string:index age:integer birth_at:datetime 'point:decimal{5,2}' 'group:references{polymorphic}' disabled:boolean salutation:text

bundle exec rails new . --name fooapp --database=sqlite3 --skip-docker --asset-pipeline=propshaft
bundle exec rubocop --show-cops | awk '!/ +- /{a=0}; /Exclude/||/^[A-Z]/{ a=1 }; a' | tac | awk 'a; /^[A-Z]/{a=0}; !a&&/^ /{a=1; print};' | tac  ## get rubocop exclude options

rg --color=never -l '^class \w.+::' app/controllers | xargs -I{} vim -Nens +'norm ggGI  ' +'norm ggWd2f:Omodule pxx' +'norm Goend' +wq {}  ## rails class replace to module

kill -9 $(cat tmp/pids/server.pid); rm tmp/pids/server.pid

# python
python3 -m http.server 8080
pyenv install 3.12.0
pyenv virtualenv 3.12.0 3.12.0-vname

# nodejs
yarn jest --watch --config 'test/jest-e2e.json' 'test/XXX.e2e-spec.ts' -t 'it_name'
npx playwright codegen ${URL}

# docker
curl host.docker.internal  ## request host in docker image
curl -XGET -s -o /dev/null -w "%{http_code}" "http://example.com"  ## check http status code
curl --head "http://example.com"  ## fetch head only
curl 'https://endoflife.date/api/amazon-eks.json' | jq -r '(["cycle", "release", "eol"], (.[] | [.cycle, .releaseDate, .eol])) | @tsv' | column -ts $'\t'  ## EOL EKS

curl -X POST --data '{"jsonrpc":"2.0","id":1,"method" :"info.peers"}' -H 'content-type:application/json;' localhost:9650/ext/info  ## rpc request info peers

docker run --rm -p 4444:4444 seleniarm/standalone-chromium  ## multi arch selenium
docker system df  ## check docker volume size
du -ks /var/lib/docker/containers/* | sort -n | tail  ## check docker containers size by 1KB
docker compose config | yq '.services[]|key'
docker compose ps -q ${SERVICE} | xargs docker inspect --format='{{.LogPath}}' | tail -n1 | xargs tail -f  ## docker logs from file
docker compose up
docker compose down -v --remove-orphans --timeout=10
docker compose exec -it
docker tag first:xxx second:yyy  ## rename docker tag

docker buildx build --no-cache -t 'test:test' . && docker run --rm -it 'test:test'
docker buildx create --name remote-container --driver remote tcp://remote-addr:1234
docker compose build --builder remote-container
docker buildx build --builder=remote-container --load -t image-name .

DOCKER_HOST="ssh://user@remote" docker images
docker context create remote --docker "host=ssh://user@remote"
docker --context remote ps

docker run --rm -it -e'POSTGRES_USER=postgres' -e'POSTGRES_PASSWORD=postgres' -e'POSTGRES_DB=example_db' -p '5432:5432' postgres:14.2

docker ps --format json | jq -r '([.Names, .State, .ID, .Image, .Ports] | @tsv)' | column -ts $'\t' | less -S

docker run --rm -it --network bridge mysql mysqlsh root@host.docker.internal:3306 -e 'util.checkForServerUpgrade();'

docker run --rm -it ubuntu cat /proc/sys/kernel/random/uuid | tr -d '-' | base64 | cut -b 1-22  ## generate uuid 22 char

docker run --rm -it ruby:slim bash  ## ~200MB
docker run --rm -it ruby:3-alpine sh  ## ~90MB

docker run -it --rm -e LOKI_ADDR=http://host.docker.internal:9000 grafana/logcli:2.8.11 -- query '{app!=""}'
docker run -it --rm -e LOKI_ADDR=http://host.docker.internal:9000 grafana/logcli:2.8.11 query --from '2024-04-01T16:00:00+09:00' --to '2024-04-01T16:30:00+09:00' '{app!=""}' --limit 50000 --output raw

docker run --rm -it --network my-networtk sauljabin/kaskade:latest consumer -b my-kafka:9092 -t my-topic  ## kafka tui

docker run --rm -it --net host nicolaka/netshoot  ## network swiss-army knife
docker run --rm -it --net host nicolaka/netshoot mtr 'example.com'
docker run --rm -it roninrb/ronin ronin http --shell https://example.com  ## network swiss-army knife for ruby
docker run --rm -it -p 8080:80 containous/whoami

docker run --rm -it --network localstack -p 4566:4566 -p 4510-4559:4510-4559 localstack/localstack

docker run -d -p 5000:5000 --restart always --name registry -v $(pwd)/registry-data:/var/lib/registry registry:2  ## push localhost:5000/ruby:latest

echo 'docker.io' | docker-credential-osxkeychain get


# terraform
terraform plan -out plan.out | tee plan.std.out
terraform apply plan.out   ## or TF_LOG=DEBUG or TF_LOG=TRACE

# aws
aws --cli-auto-prompt  ## aws auto prompt
aws eks update-kubeconfig --name ${CLUSTER_NAME} --profile ${PROFILE}
aws configure --profile ${PROFILE} ## region=ap-northeast-2, format=text|table|json|yaml
aws s3 ls
aws s3 ls --recursive --human-readable --summarize s3://bucket-name/directory
aws s3api get-bucket-lifecycle-configuration --bucket ${BUCKET}
aws sts get-caller-identity  ## check simply current account info
aws sts get-caller-identity --profile ${PROFILE}
aws sts get-caller-identity --query Account --output text  ## get aws account id
aws ecr get-login-password --region ${AWS_REGION} | docker login --password-stdin --username AWS ${ECR_REGISTRY}
aws ecr get-login-password | docker login --password-stdin --username AWS ${AWS_ID}.dkr.ecr.ap-northeast-2.amazonaws.com
curl -H "X-aws-ec2-metadata-token: $(curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600")" -v "http://169.254.169.254/latest/meta-data/placement/availability-zone-id"  ## IMDSv2 get aws instance az, metadata: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html
curl http://checkip.amazonaws.com/  ## get current ip
curl http://ip-ranges.amazonaws.com/ip-ranges.json  ## available AWS public ip pool
aws eks describe-addon-versions --kubernetes-version 1.23 --addon-name coredns --output yaml | grep 'addonVersion:' | head  ## kube-proxy, vpc-cni, coredns, aws-ebs-csi-driver
aws ec2 describe-instances --query 'Reservations[*].Instances[*].[Tags[?Key==`Name`].Value|[0],InstanceId,InstanceType,PrivateIpAddress,PublicIpAddress,State.Name]' --output text
aws ec2 describe-instances --filters 'Name=tag:Name,Values=name_*' --query 'Reservations[*].Instances[*]'  ## .[InstanceId,PrivateIpAddress]
aws ec2 describe-instance-types --query 'InstanceTypes[*].[InstanceType, MemoryInfo.SizeInMiB, VCpuInfo.DefaultVCpus]' --output text | grep -e '^m' | sort -k3 -n
aws ec2 describe-images --owners amazon --region ap-northeast-2 | jq '.[][] | [.Architecture, .ImageId, .Description]'  ## get AMI

aws eks list-nodegroups --cluster-name ${NAME} | grep 129_2x
aws eks update-nodegroup-config --cluster-name ${NAME} --nodegroup-name ${NGNAME} --scaling-config desiredSize=0

aws lightsail get-bundles
aws lightsail get-blueprints

# kubectl
kubectl get pod -A -o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,IMAGE:.spec.containers[].image'
kubectl get node --sort-by='.metadata.creationTimestamp'
kubectl get nodes -o custom-columns='NAME:.metadata.name,STATUS:.status.conditions[-1:].type,ZONE:.metadata.labels.topology\.kubernetes\.io/zone,NODE_GROUP:.metadata.labels.eks\.amazonaws\.com/nodegroup' | v -
NS=apps envsubst < service.yml | kubectl apply -f -
kubectl auth can-i "*" "*"  ## 권한 체크
kubectl api-resources --verbs=list  ## all resources
docker run -it --rm -v "$HOME/.kube:/.kube" bitnami/kubectl version
export EKS_ENDPOINT=
export EKS_TOKEN=
docker run --rm -e EKS_SERVER=$(aws eks describe-cluster --name $EKS_CLUSTER | jq -r '.cluster.endpoint') -e EKS_TOKEN=$(aws --region ap-northeast-2 eks get-token --cluster-name $EKS_CLUSTER | jq -r '.status.token') bitnami/kubectl --server $EKS_SERVER --token $EKS_TOKEN --insecure-skip-tls-verify version

kubectl run mysql-console --restart=Never -i --tty --attach --rm --image mysql --command -- bash
kubectl run psql-console --restart=Never -i --tty --attach --rm --image postgres --command -- bash
kubectl run ubuntu-console --restart=Never -i --tty --attach --rm --image ubuntu --command -- bash
kubectl create deployment whoami --image=containous/whoami
kubectl expose deployment whoami --type=NodePort --port=80 --target-port=80
kubectl expose deployment whoami --name=whoami-lb --type=LoadBalancer --port=80 --target-port=80

kubectl wait --timeout 10m --for=condition=Ready -f pod.yaml
kubectl kurt all  ## restart tracker
kubectl outdated
kubectl oomd -A  ## Check out of memory
kubectl resource-capacity --util --pods
kubectl ktop  ## resource check
v ~/.local/state/k9s/screen-dumps/  ## k9s log

htpasswd -c auth username && kubectl create secret generic basic-auth --from-file=auth  ## create basic auth secret. https://kubernetes.github.io/ingress-nginx/examples/auth/basic/
htpasswd -nB username

# helm
helm show values --version ${VER} -n ${NS} ${CHART}
helm get values ${RELEASE_NAME}  ## helm으로 반영된 values.yaml 파일 가져오기
helm ls -a -n ${NS}  ## 특정 네임스페이스의 헬름 차트 인스턴스 목록 띄우기. -A 로 전체 목록
helm diff upgrade ${NAME} ${CHART_REPO} --values=values.yaml --debug --allow-unreleased  ## 반영될 maniftest 확인

nova find --helm --format table --wide

# perl
perl -MIO::Socket::INET -e '$sock=IO::Socket::INET->new(PeerAddr=>"google.com",PeerPort=>"80",Proto=>"tcp"); print $sock "GET / HTTP/1.0\nHost: google.com\n\n"; print while <$sock>'
my $s = new IO::Socket::INET(LocalAddr => "0.0.0.0:8080", Listen => 10, Reuse => 1) or die; while(my $c = $s->accept) { my $body = "Hello World!"; print $c "HTTP/1.1 200 OK\nContent-Type: text/plain\n\n$body\n"; close($c); }
STEP=01 perl -pe '$a=qq{STEP$ENV{STEP}}; /$a:rm/ and $_=qq{}; /$a\s+/ and s/^(\s+)# (.+)\s+## $a[^#\n]+/\1\2/' *.tf

| perl -MMath::BigInt -pe 's{(0x[0-9a-fA-F]+)}{Math::BigInt->from_hex($1)}ge'  ## replace hex to int

fd | perl -lne '$a=$_=~s/txt$/csv/r; print "mv $_ $a"'  ## bulk replace file names
fd -tf . 'app/views' -x perl -i -pe 's/_admin_path/_path/g' ## bulk replace file texts

perl -MTime::Piece -e 'print localtime->datetime;' ## print datetime iso8601
perl -MTime::Piece -e 'print localtime->ymd;' ## print datetime ymd

perl -MJSON::PP -e 'print decode_json( qq({ "name": "123" }) )->{ name };'
perl -MJSON::PP -e 'print encode_json( { name => 123 } );'
perl -MYAML::PP -e 'print YAML::PP->new->load_string("test: 123")->{test};'

perl -e 'for my $dir (@INC) { opendir(DIR, $dir) or next; while (my $file = readdir(DIR)) { print "$dir/$file\n" if $file =~ /\.pm$/; } closedir(DIR); }'  ## print all perl modules


# jq
| jq 'with_entries(select([.key] | inside(["abi", "bytecode", "contractName"])))'  ## select specific keys in json
| jq -r 'paths(scalars) as $p | [($p|map(tostring)|join(".")), getpath($p)] | join(": ")'  ## json flatten
| jq '.bundles[] | select(.ramSizeInGb >= 8 and .ramSizeInGb < 12)'
| jq '.blueprints[] | select(.name | test("Ubuntu"))'

# yq
| xargs -n1 yq eval-all 'select(.kind == "StatefulSet") |= (.spec.template.spec.containers[] | select(.name == "api")).image |= sub(":.+?$", ":123")'

# curl
curl --header "Host: test.example.com" http://aws-domain.elb.amazonaws.com  ## DNS 설정 없이 ingress 테스트할 때 사용
curl --proxy "http://proxy.example.com" "http://example.com"  ## proxy 테스트
curl qrcode.show -d 'test'
| curl qrcode.show -d @-
curl -sS -H "Content-Type: application/json" -d '{ "id": 1, "jsonrpc": "2.0", "method": "rpc_methods", "params": [] }' localhost:9933 | jq ## request JSON-RPC

curl 'https://country.is/4.4.4.4'  ## check ip country
curl 'https://ipinfo.io/4.4.4.4'  ## check ip info


echo -n '{"jsonrpc":"2.0","method":"eth_blockNumber","params":[],"id":1}' | socat - UNIX-CONNECT:./tmp/test.ipc
echo -n '{"jsonrpc":"2.0","method":"eth_blockNumber","params":[],"id":1}' | nc -U ./tmp/test.ipc

# git
git log --patch -S ${QUERY}  ## history search
git log --since="2024-01-01" --until="2024-12-31"  ## filter daterange
git log --since="2 weeks ago"  ## filter daterange
git commit –allow-empty -m ""
git fetch --tags  ## fetch all tags
git fetch origin tag ${TAG} --no-tags ## fetch single tag
git switch -d tags/${TAG}  ## switch to tag
git worktree add ../${PATH} ${BRANCH}
git push --set-upstream origin master
git status --short | awk '!/##/{print$2}'  ## git status file list
git merge -Xours ${branch}  ## 충돌 발생시, ours (HEAD, stage#2)를 사용한다
git mergetool --tool=nvimdiff
git checkout --their -- :g  ## git conflit 해결용, theirs (merge target, stage#3) 기준으로 맞춘다. rebase일 경우 작업물로 설정
git checkout master -- :g  ## git conflit 해결용, master로 맞춰버리기..
git show --name-only
git update-index --chmod=+x $PATH  ## git chmod
git config --global --get user.name
git config --global --get user.email
git config --global --add user.name ${NAME}
git config --global --list
git submodule update --init
git commit --allow-empty -m 'empty'
git diff node1.yaml | perl -pe 's/node1/node2/' | git apply -  ## git diff apply to another file

git remote add up git@github.com:$OWNER/$REPO.git
git rev-parse --show-toplevel  ## git root path
git rebase -r --exec "git commit --amend --no-edit --reset-author" HEAD~3  ## reset author

# gh
gh pr list --web ## open pull request github
open https://github.com/$(git remote get-url up | perl -ne 'print /:(.+).git/') ## open github
open https://github.com/$(git remote get-url up | perl -ne 'print /:(.+).git/')/pulls ## open github pr
gh pr -R $(git remote get-url up | perl -ne 'print /:(.+).git/') list  ## PR list current up remote
gh pr checkout ${NUMBER}

gh api repos/${OWNER}/${REPO}/pulls/5355  ## list pr info json
gh api repos/${OWNER}/${REPO}/pulls/5355/files  ## list pr files json
gh api repos/${OWNER}/${REPO}/pulls/5355/commits  ## list pr commit json
gh api repos/${{ github.repository }}/pulls/5355 -q '.title'  ## in github action. with `GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}`
gh api user --jq '.login'
gh auth token | clipcopy  ## get github access tokens
gh ssh-key add $KEY_FILE -t $TITLE
gh ssh-key list

gh pr checks -i5 --watch $(gh api /user --jq '.login'):$(g branch --show-current)  ## watch github pr actions
gh pr checks $(gh api /user --jq '.login'):$(g branch --show-current) | fzf | perl -ne '($r,$j)=m[https.+?github.com/(.+)/runs/.+/job/(\d+)]; $n=($r=~s@/@_@gr); $log="/tmp/github_action_${n}_${j}.log"; `gh api repos/$r/jobs/$j/logs > ${log}`; exec "nvim +AnsiEsc ${log}"'  ## github action job download log
# old: gh pr checks $(gh api /user --jq '.login'):$(g branch --show-current) | fzf | perl -ne 'm[https.+?github.com/(.+)/runs/.+/job/(\d+)]; print `gh api repos/$1/jobs/$2/logs`' > '/tmp/github_action.log' && v /tmp/github_action.log  ## github action job download log

# mise
curl https://mise.jdx.dev/install.sh | sh

# asdf
asdf plugin add $(curl 'https://github.com/asdf-vm/asdf-plugins/tree/master/plugins' | jq -r '.payload.tree.items[].name' | fzf)
asdf plugin update --all
asdf update

# redis
redis-cli -p 26379 info ## sentinel info
redis-cli -p 26379 sentinel masters ## sentinel masters

# postgres psql
PGPASSWORD='postgres' psql -h localhost -U postgres -c '\l'  ## show databases
PGPASSWORD='postgres' psql -h localhost -U postgres -c 'select * from pg_database;'  ## show databases
PGPASSWORD='postgres' psql -h localhost -U postgres -d $DB -c '\dt'  ## show tables
PGPASSWORD='postgres' psql -h localhost -U postgres -d $DB -c 'select * from pg_catalog.pg_tables'  ## show tables
PGPASSWORD='postgres' psql -h localhost -U postgres -d $DB -c '\d table_name'  ## show table columns
PGPASSWORD='postgres' psql -h localhost -U postgres -d $DB -c 'select * from table_name limit 10'  ## select
PGPASSWORD='postgres' psql -h localhost -U postgres -d $DB -c 'insert into "table_name" ("col1", "col2", ...) '" values ('val1', 'val2', ...)"  ## insert
PGPASSWORD='postgres' psql -h localhost -U postgres -d $DB ## multiline <<SQL

# network
echo 'https://url' | tee >(nslookup) >(dig) >(xargs ping -c3)  ## test network url full
dog 'https://url'  ## alternative dig
gping 'https://url'  ## alternative ping
ss  ## alternative netstat

# open
open -na RubyMine.app --args .
open -na WebStorm.app --args .
open -na 'Visual Studio Code' .

# mac
sudo defaults write /Library/Preferences/FeatureFlags/Domain/UIKit.plist redesigned_text_cursor -dict-add Enabled -bool NO  ## disable input source switch popup

# ssh
ssh -t remote "./mise x -- k9s"

# file
tar -czvf archive.tgz /path/to/directory  ## compress, gzip, verbose, filename
tar -xzvf archive.tar.gz  ## extract, gzip, verbose, filename

zip -r archive.zip /path/to/directory  ## compress, recursive, filename
unzip archive.zip  ## extract, filename
